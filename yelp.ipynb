{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// Primitive types (Int, String, etc) and Product types (case classes) encoders are\n",
    "// supported by importing this when creating a Dataset.\n",
    "\n",
    "\n",
    "// A JSON dataset is pointed to by path.\n",
    "// The path can be either a single text file or a directory storing text files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/64/a1df4440483df47381bbbf6a03119ef66515cf2e1a766d9369811575454b/pyspark-2.4.1.tar.gz (215.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 215.7MB 177kB/s eta 0:00:01    93% |█████████████████████████████▉  | 200.8MB 24.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
      "  Using cached https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/myc/Library/Caches/pip/wheels/47/9b/57/7984bf19763749a13eece44c3174adb6ae4bc95b920375ff50\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Word Count\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"yelp_academic_dataset_review.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Total bill for th...|\n",
      "|I *adore* Travis ...|\n",
      "|I have to say tha...|\n",
      "|Went in for a lun...|\n",
      "|Today was my seco...|\n",
      "|I'll be the first...|\n",
      "|Tracy dessert had...|\n",
      "|This place has go...|\n",
      "|I was really look...|\n",
      "|It's a giant Best...|\n",
      "|Like walking back...|\n",
      "|Walked in around ...|\n",
      "|Wow. So surprised...|\n",
      "|Michael from Red ...|\n",
      "|I cannot believe ...|\n",
      "+--------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"text\").show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
